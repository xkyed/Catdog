{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Found 666 images belonging to 2 classes.\n",
      "Found 666 images belonging to 2 classes.\n",
      "Found 666 images belonging to 2 classes.\n",
      "61/62 [============================>.] - ETA: 1s - loss: 5.6637 - acc: 0.6311Found 332 images belonging to 2 classes.\n",
      "Found 332 images belonging to 2 classes.\n",
      "Found 332 images belonging to 2 classes.\n",
      "62/62 [==============================] - 77s 1s/step - loss: 5.5721 - acc: 0.6371 - val_loss: 5.4086 - val_acc: 0.6626\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 78s 1s/step - loss: 4.4055 - acc: 0.5509 - val_loss: 0.7146 - val_acc: 0.4969\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 73s 1s/step - loss: 0.5888 - acc: 0.6351 - val_loss: 3.2984 - val_acc: 0.6025\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 70s 1s/step - loss: 0.8307 - acc: 0.7178 - val_loss: 1.7746 - val_acc: 0.4303\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 73s 1s/step - loss: 0.6788 - acc: 0.7703 - val_loss: 4.8046 - val_acc: 0.5369\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.5985 - acc: 0.9012 - val_loss: 4.2010 - val_acc: 0.4959\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.8484 - acc: 0.8457 - val_loss: 4.5295 - val_acc: 0.4713\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.5854 - acc: 0.8447 - val_loss: 1.1822 - val_acc: 0.5615\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.7118 - acc: 0.7711 - val_loss: 3.3661 - val_acc: 0.4057\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.6004 - acc: 0.8185 - val_loss: 0.8278 - val_acc: 0.6270\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.5710 - acc: 0.8165 - val_loss: 5.7443 - val_acc: 0.3402\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.5894 - acc: 0.9098 - val_loss: 0.8234 - val_acc: 0.6504\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 72s 1s/step - loss: 0.6168 - acc: 0.8528 - val_loss: 1.4871 - val_acc: 0.3821\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.6321 - acc: 0.6844 - val_loss: 0.8634 - val_acc: 0.5854\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.6557 - acc: 0.7157 - val_loss: 1.5877 - val_acc: 0.4472\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.6021 - acc: 0.5221 - val_loss: 0.6881 - val_acc: 0.5213\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.6331 - acc: 0.6955 - val_loss: 0.6769 - val_acc: 0.4970\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.6073 - acc: 0.6376 - val_loss: 0.6976 - val_acc: 0.4512\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.6529 - acc: 0.7580 - val_loss: 0.7617 - val_acc: 0.4228\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.5804 - acc: 0.6093 - val_loss: 0.7028 - val_acc: 0.3923\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 114s 2s/step - loss: 0.4599 - acc: 0.8074 - val_loss: 6.4741 - val_acc: 0.3577\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.6977 - acc: 0.6184 - val_loss: 1.5651 - val_acc: 0.6626\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.4903 - acc: 0.7984 - val_loss: 2.0718 - val_acc: 0.3648\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.6090 - acc: 0.6935 - val_loss: 4.3386 - val_acc: 0.6025\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.5389 - acc: 0.8518 - val_loss: 1.7107 - val_acc: 0.4303\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 70s 1s/step - loss: 0.5852 - acc: 0.6572 - val_loss: 1.5482 - val_acc: 0.5369\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.7339 - acc: 0.7510 - val_loss: 1.4971 - val_acc: 0.4959\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.5780 - acc: 0.6300 - val_loss: 2.2482 - val_acc: 0.4713\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 980s 16s/step - loss: 0.4965 - acc: 0.8286 - val_loss: 1.0918 - val_acc: 0.5615\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 81s 1s/step - loss: 0.5981 - acc: 0.5725 - val_loss: 6.0638 - val_acc: 0.4057\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.5392 - acc: 0.7974 - val_loss: 0.9830 - val_acc: 0.6270\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.4374 - acc: 0.7535 - val_loss: 0.8348 - val_acc: 0.4180\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.5788 - acc: 0.7772 - val_loss: 0.7966 - val_acc: 0.6504\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.5753 - acc: 0.6995 - val_loss: 6.5325 - val_acc: 0.3821\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.4472 - acc: 0.7893 - val_loss: 0.7952 - val_acc: 0.5854\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.5783 - acc: 0.7207 - val_loss: 0.6777 - val_acc: 0.5528\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.6539 - acc: 0.4243 - val_loss: 1.1881 - val_acc: 0.5203\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.5828 - acc: 0.6280 - val_loss: 4.1274 - val_acc: 0.5122\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.6185 - acc: 0.7086 - val_loss: 0.7909 - val_acc: 0.4512\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 2783s 45s/step - loss: 0.4821 - acc: 0.7787 - val_loss: 0.7002 - val_acc: 0.4187\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.5324 - acc: 0.5937 - val_loss: 0.7192 - val_acc: 0.3902\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.4619 - acc: 0.7943 - val_loss: 2.3730 - val_acc: 0.3577\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.7341 - acc: 0.3417 - val_loss: 0.7134 - val_acc: 0.3374\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.5076 - acc: 0.8004 - val_loss: 2.4559 - val_acc: 0.3648\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.7415 - acc: 0.3739 - val_loss: 0.7058 - val_acc: 0.4016\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 72s 1s/step - loss: 1.8217 - acc: 0.6663 - val_loss: 1.5128 - val_acc: 0.4303\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 74s 1s/step - loss: 0.6506 - acc: 0.4787 - val_loss: 4.0330 - val_acc: 0.5369\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.5796 - acc: 0.6240 - val_loss: 1.5068 - val_acc: 0.4959\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 2274s 37s/step - loss: 0.5720 - acc: 0.7328 - val_loss: 7.1308 - val_acc: 0.4713\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 75s 1s/step - loss: 0.6229 - acc: 0.6299 - val_loss: 1.1023 - val_acc: 0.5615\n",
      "9572.827181100845\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "session_conf = tf.ConfigProto(\n",
    "      intra_op_parallelism_threads=1,\n",
    "      inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(config=session_conf)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "    # dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train1_data_dir = 'data/train1'\n",
    "train2_data_dir = 'data/train2'\n",
    "train3_data_dir = 'data/train3'\n",
    "val1_data_dir = 'data/val1'\n",
    "val2_data_dir = 'data/val2'\n",
    "val3_data_dir = 'data/val3'\n",
    "nb_train_samples = 999\n",
    "nb_validation_samples = 501\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mergedOut = Add()([model1.output,model2.output,model3.output])\n",
    "\n",
    "mergedOut = Flatten()(mergedOut)    \n",
    "mergedOut = Dense(64, activation='relu')(mergedOut)\n",
    "mergedOut = Dropout(.5)(mergedOut)\n",
    "mergedOut = Dense(2, activation='sigmoid')(mergedOut)\n",
    "\n",
    "model = Model([model1.input,model2.input,model3.input], mergedOut)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "def generate_generator_multiple(generator,dir1, dir2, dir3, batch_size, img_height,img_width):\n",
    "    genX1 = generator.flow_from_directory(dir1,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          seed=7)\n",
    "    \n",
    "    genX2 = generator.flow_from_directory(dir2,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          seed=7)\n",
    "    \n",
    "    genX3 = generator.flow_from_directory(dir3,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          seed=7)\n",
    "    \n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            X3i = genX3.next()\n",
    "            yield [X1i[0], X2i[0], X3i[0]], X3i[1]  #Yield both images and their mutual label\n",
    "            \n",
    "            \n",
    "train_generator=generate_generator_multiple(generator=train_datagen,\n",
    "                                           dir1=train1_data_dir,\n",
    "                                           dir2=train2_data_dir,\n",
    "                                           dir3=train3_data_dir,\n",
    "                                           batch_size=batch_size,\n",
    "                                           img_height=img_height,\n",
    "                                           img_width=img_height)       \n",
    "\n",
    "\n",
    "validation_generator=generate_generator_multiple(generator=test_datagen,\n",
    "                                          dir1=val1_data_dir,\n",
    "                                          dir2=val2_data_dir,\n",
    "                                          dir3=val3_data_dir,\n",
    "                                          batch_size=batch_size,\n",
    "                                          img_height=img_height,\n",
    "                                          img_width=img_height) \n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save('seq_try.h5')\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "    \n",
    "print(total)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
